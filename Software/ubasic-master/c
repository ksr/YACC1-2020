 load done
File
1 print "start"
10 let a=1
20 print a
30 let b=2
40 print b
99 end 

 done 
File
1 print "start"
10 gosub 100
20 for i = 1 to 10
30 print i
25 print "before"
40 next i
50 print "end"
60 end
100 print "subroutine"
105 print 2+3*4+5
106 print 2
107 print ( 2 + 3 ) * ( 4 + 5 ) 
108 print 3
110 return

 done 
tokenizer_init
tokenizer_goto
get_next_token(): '1 print "start"
10 let a=1
20 print a
30 let b=2
40 print b
99 end 
'
tokenizer_goto 2
get_next_token(): '1 print "start"
10 let a=1
20 print a
30 let b=2
40 print b
99 end 
'
tokenizer_init 2
tokenizer_next: 0x7ffeed44f3c1
get_next_token(): 'print "start"
10 let a=1
20 print a
30 let b=2
40 print b
99 end 
'
tokenizer_next: 'print "start"
10 let a=1
20 print a
30 let b=2
40 print b
99 end 
' 6
tokenizer_next: 0x7ffeed44f3c7
get_next_token(): '"start"
10 let a=1
20 print a
30 let b=2
40 print b
99 end 
'
tokenizer_next: '"start"
10 let a=1
20 print a
30 let b=2
40 print b
99 end 
' 3
starttokenizer_next: 0x7ffeed44f3cf
get_next_token(): '
10 let a=1
20 print a
30 let b=2
40 print b
99 end 
'
tokenizer_next: '
10 let a=1
20 print a
30 let b=2
40 print b
99 end 
' 36

tokenizer_next: 0x7ffeed44f3d0
get_next_token(): '10 let a=1
20 print a
30 let b=2
40 print b
99 end 
'
tokenizer_next: '10 let a=1
20 print a
30 let b=2
40 print b
99 end 
' 2
tokenizer_next: 0x7ffeed44f3d2
get_next_token(): 'let a=1
20 print a
30 let b=2
40 print b
99 end 
'
tokenizer_next: 'let a=1
20 print a
30 let b=2
40 print b
99 end 
' 5
tokenizer_next: 0x7ffeed44f3d6
get_next_token(): 'a=1
20 print a
30 let b=2
40 print b
99 end 
'
tokenizer_next: 'a=1
20 print a
30 let b=2
40 print b
99 end 
' 4
tokenizer_next: 0x7ffeed44f3d8
get_next_token(): '=1
20 print a
30 let b=2
40 print b
99 end 
'
tokenizer_next: '=1
20 print a
30 let b=2
40 print b
99 end 
' 35
tokenizer_next: 0x7ffeed44f3d9
get_next_token(): '1
20 print a
30 let b=2
40 print b
99 end 
'
tokenizer_next: '1
20 print a
30 let b=2
40 print b
99 end 
' 2
tokenizer_next: 0x7ffeed44f3da
get_next_token(): '
20 print a
30 let b=2
40 print b
99 end 
'
tokenizer_next: '
20 print a
30 let b=2
40 print b
99 end 
' 36
tokenizer_next: 0x7ffeed44f3db
get_next_token(): '20 print a
30 let b=2
40 print b
99 end 
'
tokenizer_next: '20 print a
30 let b=2
40 print b
99 end 
' 2
tokenizer_next: 0x7ffeed44f3dd
get_next_token(): 'print a
30 let b=2
40 print b
99 end 
'
tokenizer_next: 'print a
30 let b=2
40 print b
99 end 
' 6
tokenizer_next: 0x7ffeed44f3e3
get_next_token(): 'a
30 let b=2
40 print b
99 end 
'
tokenizer_next: 'a
30 let b=2
40 print b
99 end 
' 4
tokenizer_next: 0x7ffeed44f3e5
get_next_token(): '
30 let b=2
40 print b
99 end 
'
tokenizer_next: '
30 let b=2
40 print b
99 end 
' 36
1
tokenizer_next: 0x7ffeed44f3e6
get_next_token(): '30 let b=2
40 print b
99 end 
'
tokenizer_next: '30 let b=2
40 print b
99 end 
' 2
tokenizer_next: 0x7ffeed44f3e8
get_next_token(): 'let b=2
40 print b
99 end 
'
tokenizer_next: 'let b=2
40 print b
99 end 
' 5
tokenizer_next: 0x7ffeed44f3ec
get_next_token(): 'b=2
40 print b
99 end 
'
tokenizer_next: 'b=2
40 print b
99 end 
' 4
tokenizer_next: 0x7ffeed44f3ee
get_next_token(): '=2
40 print b
99 end 
'
tokenizer_next: '=2
40 print b
99 end 
' 35
tokenizer_next: 0x7ffeed44f3ef
get_next_token(): '2
40 print b
99 end 
'
tokenizer_next: '2
40 print b
99 end 
' 2
tokenizer_next: 0x7ffeed44f3f0
get_next_token(): '
40 print b
99 end 
'
tokenizer_next: '
40 print b
99 end 
' 36
tokenizer_next: 0x7ffeed44f3f1
get_next_token(): '40 print b
99 end 
'
tokenizer_next: '40 print b
99 end 
' 2
tokenizer_next: 0x7ffeed44f3f3
get_next_token(): 'print b
99 end 
'
tokenizer_next: 'print b
99 end 
' 6
tokenizer_next: 0x7ffeed44f3f9
get_next_token(): 'b
99 end 
'
tokenizer_next: 'b
99 end 
' 4
tokenizer_next: 0x7ffeed44f3fb
get_next_token(): '
99 end 
'
tokenizer_next: '
99 end 
' 36
2
tokenizer_next: 0x7ffeed44f3fc
get_next_token(): '99 end 
'
tokenizer_next: '99 end 
' 2
tokenizer_next: 0x7ffeed44f3fe
get_next_token(): 'end 
'
tokenizer_next: 'end 
' 20
tokenizer_next: 0x7ffeed44f402
get_next_token(): '
'
tokenizer_next: '
' 36
